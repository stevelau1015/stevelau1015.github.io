<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
    <id>https://stevelau1015.github.io</id>
    <title>Gridea</title>
    <updated>2021-04-06T12:12:50.517Z</updated>
    <generator>https://github.com/jpmonette/feed</generator>
    <link rel="alternate" href="https://stevelau1015.github.io"/>
    <link rel="self" href="https://stevelau1015.github.io/atom.xml"/>
    <subtitle>温故而知新</subtitle>
    <logo>https://stevelau1015.github.io/images/avatar.png</logo>
    <icon>https://stevelau1015.github.io/favicon.ico</icon>
    <rights>All rights reserved 2021, Gridea</rights>
    <entry>
        <title type="html"><![CDATA[树莓派内核编译]]></title>
        <id>https://stevelau1015.github.io/post/shu-mei-pai-nei-he-bian-yi/</id>
        <link href="https://stevelau1015.github.io/post/shu-mei-pai-nei-he-bian-yi/">
        </link>
        <updated>2021-04-06T05:51:10.000Z</updated>
        <content type="html"><![CDATA[<p>最近在系统地学习嵌入式，把这篇之前写过的文档先update上来</p>
<h2 id="为什么要使用内核编译">为什么要使用内核编译</h2>
<p>在编译链接同等规模的代码时，PC机所用的时间应少于树莓派所用时间，通过交叉编译的方法能提高速度。</p>
<h3 id="建立交叉编译环境">建立交叉编译环境</h3>
<p>建立交叉编译环境就是在PC机上安装能够编译树莓派软件的工具链，进行树莓派软件的编译。</p>
<p>工作分为两步，下载交叉编译器和设置环境变量。</p>
<h4 id="1下载安装树莓派交叉编译器">1.下载安装树莓派交叉编译器</h4>
<p>首先下载必要的软件和工具</p>
<pre><code class="language-bash">sudo apt-get install build-essential git
</code></pre>
   <img src="C:\Users\leon lau\AppData\Roaming\Typora\typora-user-images\image-20210325225235255.png" alt="1.1下载必要的工具" style="zoom:67%;" />
<center>图1.1 下载git相关工具并解压</center>
<pre><code class="language-bash">#在home路径下建立一个文件夹取名为rpi
mkdir rpi
#进入该目录并执行clone操作
cd rpi
git clone git://github.com/raspberrypi/tools.git
#进入tools下的arm-bcm2708子目录，交叉编译器在此目录下。
cd ~/rpi/tools/arm-bcm2708/
#64位系统使用的工具所在文件夹为 
$(gcc-linaro-arm-linux-gnueabihf-raspbian-x64)
</code></pre>
<img src="C:\Users\leon lau\AppData\Roaming\Typora\typora-user-images\image-20210325230622364.png" alt="image-20210325230622364"  />
<center>图1.2 建立目录并找到交叉编译器所在位置</center>
<h4 id="2设置环境变量">2.设置环境变量</h4>
<p>在<code>/.bashrc</code>文件中加入<code>gcc</code>交叉工具链目录。</p>
<pre><code class="language-bash">sudo nano ~/.bashrc
</code></pre>
<p>打开一个隐藏文件，在该文件最后一行加入交叉工具链所在目录。</p>
<pre><code class="language-bash">export PATH=$PATH:$HOME/rpi/tools/arm-bcm2708/gcc-linaro-arm-linux-gnueabihf-raspbian-x64/bin
</code></pre>
<p>请注意<code>~</code>符号表示<code>HOME</code>路径，<code>.bashrc</code>为隐藏文件。注意<code>PATH</code>代表环境变量，<code>:</code>冒号代表追加。<code>x</code>是小写的。</p>
<p>![image-20210325233216305](C:\Users\leon lau\AppData\Roaming\Typora\typora-user-images\image-20210325233216305.png)</p>
<center>图2.1 加入交叉工具链所在目录</center>
<p><code>Ctrl-O</code>保存并退出文件，接着执行以下指令以便立即更新当前控制台所包含的环境变量。</p>
<pre><code class="language-bash">source .bashrc
</code></pre>
<p>![image-20210325231723275](C:\Users\leon lau\AppData\Roaming\Typora\typora-user-images\image-20210325231723275.png)</p>
<center>图2.2 执行命令更新环境变量</center>
<p>为了测试交叉工具链是否安装成功，可在控制台中输入：</p>
<pre><code class="language-bash">arm-linux-gnueabihf-gcc -v
</code></pre>
<p>得到下图，证明交叉工具链安装成功。</p>
<p>![image-20210325233013224](C:\Users\leon lau\AppData\Roaming\Typora\typora-user-images\image-20210325233013224.png)</p>
<center>图2.3 验证交叉工具链是否安装成功</center>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[时间序列分析]]></title>
        <id>https://stevelau1015.github.io/post/time-series-analysis/</id>
        <link href="https://stevelau1015.github.io/post/time-series-analysis/">
        </link>
        <updated>2021-01-21T12:10:05.000Z</updated>
        <content type="html"><![CDATA[<h1 id="时间序列">时间序列</h1>
<h2 id="stationary">Stationary</h2>
<h3 id="如何定义stationary">如何定义stationary：</h3>
<p>均值、方差为常数，不包含周期性（季节性？）<br>
<img src="https://img-blog.csdnimg.cn/20210111164423841.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NDg4ODM1NA==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述" loading="lazy"></p>
<h3 id="如何检验是否stationary">如何检验是否stationary</h3>
<p>non-stationary的一些反例<br>
<img src="https://img-blog.csdnimg.cn/20210111164826533.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NDg4ODM1NA==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述" loading="lazy"></p>
<h3 id="如何把不stat变stat用高维变量">如何把不stat变stat，用高维变量</h3>
<h2 id="白噪音">白噪音</h2>
<p>三个条件全部满足的称为白噪音<br>
<img src="https://img-blog.csdnimg.cn/20210111220331296.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NDg4ODM1NA==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述" loading="lazy"><br>
实际分析的是signal<br>
<img src="https://img-blog.csdnimg.cn/20210111220417716.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NDg4ODM1NA==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述" loading="lazy"></p>
<h2 id="autoregressive-model">Autoregressive Model</h2>
<p>PACF 实际上忽略了band内（红线），取了band外的部分作为特征（自变量）建立模型。</p>
<h1 id="问题-这个柱状图的纵坐标就是销量吗">问题  这个柱状图的纵坐标就是销量吗？</h1>
<figure data-type="image" tabindex="1"><img src="https://img-blog.csdnimg.cn/20210111220725967.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NDg4ODM1NA==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述" loading="lazy"></figure>
<h2 id="移动平均模型-moving-average">移动平均模型 moving average</h2>
<p>疯子教授<br>
窗口移动，平均值不变，本图均为10<br>
MA（2）：与前两个月有关。<br>
上式代表我的预测<br>
下式代表真实的值，两者的区别只是一个error epsilon ε<br>
<img src="https://img-blog.csdnimg.cn/20210111222436596.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NDg4ODM1NA==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述" loading="lazy"></p>
<h1 id="arma">ARMA</h1>
<p>一部分AR（小线性和前月销量有关）  一部分MA（和前月错误ε有关）<br>
<img src="https://img-blog.csdnimg.cn/2021011123043771.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NDg4ODM1NA==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述" loading="lazy"><br>
选择ARMA（ ar，ma）的参数，AR的参数由PACF确定，MA的参数由ACF确定<br>
<img src="https://img-blog.csdnimg.cn/20210111232711465.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NDg4ODM1NA==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述" loading="lazy"></p>
<h1 id="arima">ARIMA</h1>
<p>i integrand 用来满足stationary这个要求<br>
用后月减前月的值变成新的Y<br>
<img src="https://img-blog.csdnimg.cn/20210111232457419.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NDg4ODM1NA==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述" loading="lazy"><br>
完整的表达式（见右侧橘色部分）以及已知Zt如何倒推回At<br>
<img src="https://img-blog.csdnimg.cn/20210111233534835.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NDg4ODM1NA==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述" loading="lazy"></p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[cs229 机器学习笔记]]></title>
        <id>https://stevelau1015.github.io/post/cs229-notes/</id>
        <link href="https://stevelau1015.github.io/post/cs229-notes/">
        </link>
        <updated>2021-01-08T08:38:34.000Z</updated>
        <content type="html"><![CDATA[<h1 id="cs229-学习笔记">CS229 学习笔记</h1>
<h2 id="梯度下降应该同步更新">梯度下降应该同步更新</h2>
<p>缺少图片</p>
<h2 id="lr-设置要合理">lr 设置要合理</h2>
<figure data-type="image" tabindex="1"><img src="https://img-blog.csdnimg.cn/20210108163016212.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NDg4ODM1NA==,size_16,color_FFFFFF,t_70" alt="" loading="lazy"></figure>
<h3 id="评价函数里对所有样本做了遍历于是为bgd-batch">评价函数里对所有样本做了遍历，于是为BGD Batch</h3>
<figure data-type="image" tabindex="2"><img src="https://img-blog.csdnimg.cn/20210108163209784.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NDg4ODM1NA==,size_16,color_FFFFFF,t_70" alt=" batch" loading="lazy"></figure>
<h1 id="奇异矩阵没有逆矩阵">奇异矩阵没有逆矩阵</h1>
<figure data-type="image" tabindex="3"><img src="https://img-blog.csdnimg.cn/20210108163253317.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NDg4ODM1NA==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述" loading="lazy"></figure>
<h2 id="特征缩放">特征缩放</h2>
<figure data-type="image" tabindex="4"><img src="https://img-blog.csdnimg.cn/20210108163332197.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NDg4ODM1NA==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述" loading="lazy"></figure>
<h3 id="平均标准化">平均标准化<img src="https://img-blog.csdnimg.cn/20210108163347730.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NDg4ODM1NA==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述" loading="lazy"></h3>
<h2 id="画这个图像来确认梯度下降是否收敛">画这个图像来确认梯度下降是否收敛</h2>
<figure data-type="image" tabindex="5"><img src="https://img-blog.csdnimg.cn/20210108163528164.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NDg4ODM1NA==,size_16,color_FFFFFF,t_70" alt="画这个图像来确认梯度下降是否收敛" loading="lazy"></figure>
<h3 id="设置合适的学习率不然梯度下降效率会很慢">设置合适的学习率，不然梯度下降效率会很慢</h3>
<figure data-type="image" tabindex="6"><img src="https://img-blog.csdnimg.cn/20210108163701302.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NDg4ODM1NA==,size_16,color_FFFFFF,t_70" alt="合适的学习率，不然梯度下降效率会很慢" loading="lazy"></figure>
<h2 id="octave教学">Octave教学</h2>
<figure data-type="image" tabindex="7"><img src="https://img-blog.csdnimg.cn/20210108163732959.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NDg4ODM1NA==,size_16,color_FFFFFF,t_70" alt="高斯分布" loading="lazy"></figure>
<h2 id="normal-equation-正规方程">Normal Equation 正规方程</h2>
<p>每行1个样本 包含了样本1的好多个feature<br>
每个点是一个feature的值<br>
<img src="https://img-blog.csdnimg.cn/20210108174838623.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NDg4ODM1NA==,size_16,color_FFFFFF,t_70" alt="X矩阵 设计矩阵 每行1个样本 每个点是一个feature的值" loading="lazy"></p>
<h2 id="用normal-equation时缩放是没有必要的">用normal equation时，缩放是没有必要的</h2>
<figure data-type="image" tabindex="8"><img src="https://img-blog.csdnimg.cn/20210108175558775.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NDg4ODM1NA==,size_16,color_FFFFFF,t_70" alt="normal equation 左上" loading="lazy"></figure>
<h1 id="logistic-regression-新cost-函数来自于极大似然估计">logistic regression 新cost 函数来自于极大似然估计</h1>
<figure data-type="image" tabindex="9"><img src="https://img-blog.csdnimg.cn/20210109093625358.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NDg4ODM1NA==,size_16,color_FFFFFF,t_70" alt="极大似然估计" loading="lazy"></figure>
<h3 id="和linear-regression-的区别在于hx的假设不一样了">和linear regression 的区别在于h(x)的假设不一样了</h3>
<p><img src="https://img-blog.csdnimg.cn/20210109094042619.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NDg4ODM1NA==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述" loading="lazy"><br>
相当于把非线性的sigmoid函数塞进了h（x）里<br>
线搜索使得不需要手动调整α<br>
<img src="https://img-blog.csdnimg.cn/20210109094622667.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NDg4ODM1NA==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述" loading="lazy"></p>
<h3 id="多分类问题">多分类问题</h3>
<p>输入相同只需要把三个分类器里算出的值比较一下，找出值最大的那一个分类器，那么将被分入这个分类器对应的那一类<br>
<img src="https://img-blog.csdnimg.cn/20210109100754795.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NDg4ODM1NA==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述" loading="lazy"></p>
<h2 id="overfitting-high-variance-过拟合高方差">overfitting  High variance 过拟合=高方差</h2>
<p>泛化能力，模型应用到新样本的能力<br>
<img src="https://img-blog.csdnimg.cn/2021010910141780.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NDg4ODM1NA==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述" loading="lazy"><br>
如何识别overfitting 后期会学习<br>
如何解决overfitting<br>
两种方法 1：减少feature数量<br>
2：正则化 regularization（每个feature贡献一部分模型）		<img src="https://img-blog.csdnimg.cn/20210109101929124.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NDg4ODM1NA==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述" loading="lazy"><br>
正则化：加了一些惩罚项，目标是最小化等号右边的式子，只有θ3和θ4接近于零的时候才让等号右边的式子最小<br>
<img src="https://img-blog.csdnimg.cn/20210109102312926.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NDg4ODM1NA==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述" loading="lazy"><br>
正则化必定可以让normal equation 的前面这一项变得可逆<br>
<img src="https://img-blog.csdnimg.cn/20210109103716604.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NDg4ODM1NA==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述" loading="lazy"><br>
对所有正则化来说，lamda是用来取舍fit the trainset 和 generalization的一种办法，一种比重，一种比例</p>
<h1 id="神经网络">神经网络</h1>
<p><img src="https://img-blog.csdnimg.cn/20210109111207288.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NDg4ODM1NA==,size_16,color_FFFFFF,t_70" alt="数学假设" loading="lazy"><br>
右上角是层数，线性，sigmoid，再线性，再sigmoid，输出</p>
<h2 id="cost-function-lesson-9-1">cost function （lesson 9-1）</h2>
<p>一大坨和<br>
<img src="https://img-blog.csdnimg.cn/20210109173830711.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NDg4ODM1NA==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述" loading="lazy"></p>
<h2 id="后向传播-lesson-9-2">后向传播 （lesson 9-2）</h2>
<p>左下到右下的数学推导欠缺。<br>
但是可以利用a和δ求出偏导<br>
<img src="https://img-blog.csdnimg.cn/20210109173523735.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NDg4ODM1NA==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述" loading="lazy"></p>
<h3 id="具体实现的流程">具体实现的流程</h3>
<p>不需要δ（1）和δ（L） ：输入层和输出层没有误差<br>
<img src="https://img-blog.csdnimg.cn/20210109174241730.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NDg4ODM1NA==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述" loading="lazy"><br>
j=0，对应着偏差项，无需正则化<br>
<img src="https://img-blog.csdnimg.cn/20210109174538200.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NDg4ODM1NA==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述" loading="lazy"><br>
最后算出来一个D值，就是损失函数里的偏导项，可以在这个基础上继续梯度下降<img src="https://img-blog.csdnimg.cn/20210109174734539.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NDg4ODM1NA==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述" loading="lazy"></p>
<h2 id="零初始化的重要性全部一样的初始权重将导致一模一样的输入结果所有网络节点都一样计算没有意义">零初始化的重要性，全部一样的初始权重将导致一模一样的输入结果，所有网络节点都一样，计算没有意义</h2>
<h1 id="建议的策略-不要过早优化">建议的策略 不要过早优化</h1>
<figure data-type="image" tabindex="10"><img src="https://img-blog.csdnimg.cn/20210110181048782.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NDg4ODM1NA==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述" loading="lazy"></figure>
<h1 id="误差分析">误差分析</h1>
<figure data-type="image" tabindex="11"><img src="https://img-blog.csdnimg.cn/20210110181519866.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NDg4ODM1NA==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述" loading="lazy"></figure>
<h1 id="不均衡的分类问题-skewed">不均衡的分类问题 skewed</h1>
<p>把较少的那一类设置为y=1 ，阳性类，由此得出precision和recall很难欺骗我们。<br>
<img src="https://img-blog.csdnimg.cn/20210110183607503.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NDg4ODM1NA==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述" loading="lazy"></p>
<h2 id="precision和recall的权衡">precision和recall的权衡</h2>
<p>高 precision 设置阈值（threshold）为0.7<br>
高 recall 设置阈值为0.3<br>
<img src="https://img-blog.csdnimg.cn/20210110183359334.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NDg4ODM1NA==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述" loading="lazy"><br>
用一个积在河上非的F1score去评价precision和recall的权衡<br>
<img src="https://img-blog.csdnimg.cn/20210111144710173.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NDg4ODM1NA==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述" loading="lazy"></p>
<h1 id="是否需要更大的数据集">是否需要更大的数据集</h1>
<p>当人类专家能从给定信息里判断，那么不需要<br>
<img src="https://img-blog.csdnimg.cn/20210110185218257.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NDg4ODM1NA==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述" loading="lazy"><br>
更大的数据集通常用来使系统 low variance<br>
复杂的算法使系统 low bias<br>
<img src="https://img-blog.csdnimg.cn/20210110185512263.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NDg4ODM1NA==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述" loading="lazy"></p>
<h1 id="12-1-svm">12-1 Svm</h1>
<p>SVM和LR的区别：损失函数做了替换，正则项的系数更考虑贴合前一项，也就是更考虑和样本的符合程度。<br>
<img src="https://img-blog.csdnimg.cn/20210215112322391.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NDg4ODM1NA==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述" loading="lazy"></p>
<h2 id="12-2-svm-c不太大的时候会合理忽略异常大间隔导致了鲁棒性用尽量大的间隔把样本分开">12-2 svm C不太大的时候会合理忽略异常，大间隔导致了鲁棒性，用尽量大的间隔把样本分开</h2>
<h2 id="12-3-θ_0-0边界过原点-时候的分类效果数学推导">12-3 θ_0 = 0(边界过原点） 时候的分类效果，数学推导</h2>
<p>设置边界如左将使得正负两样本投影到θ上的向量变小，这样使得为满足s.t.的话，θ的模的平方，势必要很大，不符合第一行minimal 的假设。所以能看出SVM是大间隔的分类器，为了让p_1,p_2.p_3（间隔margin）更大。<br>
<img src="https://img-blog.csdnimg.cn/20210215120106497.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NDg4ODM1NA==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述" loading="lazy"></p>
<h1 id="跳过了12-1~13-5的svm和k-means聚类待补充共11个视频">跳过了12-1~13-5的SVM和K-means聚类（待补充）共11个视频</h1>
<h1 id="降维pca-主成分分析">降维：PCA 主成分分析</h1>
<p>formula：目的是找到一个向量，使得所有点投影到这个方向上延伸的直线的投影距离最短<br>
<img src="https://img-blog.csdnimg.cn/2021011114492386.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NDg4ODM1NA==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述" loading="lazy"><br>
pca不是linear regression<br>
计算误差的方式不一样，linear是算竖直距离；PCA求的是最短距离<br>
<img src="https://img-blog.csdnimg.cn/20210111145246450.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NDg4ODM1NA==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述" loading="lazy"><br>
有字幕版本的14-5 https://www.bilibili.com/video/av95751735</p>
<h2 id="如何查看合适的维度选择降到几维呢">如何查看合适的维度，选择降到几维呢？</h2>
<p>用svd解出的S值，就可以算出协方差，covariance是否小于0.05/0.01，得到合理的K值<br>
<img src="https://img-blog.csdnimg.cn/20210111151925385.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NDg4ODM1NA==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述" loading="lazy"><br>
<img src="https://img-blog.csdnimg.cn/20210111152405951.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NDg4ODM1NA==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述" loading="lazy"></p>
<h2 id="恢复压缩">恢复压缩</h2>
<p>两边左乘一个svd中的U<br>
<img src="https://img-blog.csdnimg.cn/20210111153010877.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NDg4ODM1NA==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述" loading="lazy"></p>
]]></content>
    </entry>
</feed>